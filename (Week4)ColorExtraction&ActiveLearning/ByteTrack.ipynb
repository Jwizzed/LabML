{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84feb8f3-0707-4317-b99d-b02d7636c89b",
   "metadata": {},
   "source": [
    "# Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bc04f37-2b0f-4f26-9956-955553eb21a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\USER\\\\Downloads\\\\DeepFashion2\\\\DeepFashion2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import supervision as sv\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "HOME = os.getcwd()\n",
    "HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725bc1d3-e123-46c2-8cd6-1aed1f57305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics supervision --upgrade supervision\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653daf3a-d503-4a0c-91ca-fad27376e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"{HOME}/yolov9/deepfashion2-m-11k-1\"\n",
    "IMAGE_PATH = f\"{HOME}/yolov9/deepfashion2-m-11k-1/train/images\"\n",
    "WEIGHT_PATH = f\"{HOME}/yolov9/weights/yolov9c.pt\"\n",
    "# SINGLE_IMAGE = IMAGE_PATH + \"/000001_png.rf.3efc63de2fe2bab8882abc87437bf048.jpg\"\n",
    "SINGLE_IMAGE = \"yolov9/mytest/5.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2c3a2-9e08-4547-a578-dc3bee72f5a3",
   "metadata": {},
   "source": [
    "# Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4931546a-c014-4195-9b27-fdc8bba85342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv9c summary: 618 layers, 25590912 parameters, 0 gradients, 104.0 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(618, 25590912, 0, 104.02268160000003)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(WEIGHT_PATH)\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3673d92-8052-4fa0-a588-a6c340f38671",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156b8bb6-12e6-400e-b1ef-5280fe84eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_video_path = f\"{HOME}/yolov9/myvid/background video _ people _ walking _.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbda20-e6c1-4cb6-bf82-1c32edce6027",
   "metadata": {},
   "source": [
    "# ByteTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cfc0526-9961-4623-82b2-22be23de59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_ANNOTATOR = sv.ColorAnnotator()\n",
    "LABEL_ANNOTATOR = sv.LabelAnnotator(text_color=sv.Color.from_hex(\"#000000\"))\n",
    "tracker = sv.ByteTrack(minimum_matching_threshold=0.5)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81cc19e7-8172-4b22-b1f5-da3f5206b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = sv.VideoInfo.from_video_path(video_path=source_video_path)\n",
    "frames_generator = sv.get_video_frames_generator(source_video_path)\n",
    "\n",
    "frame = next(frames_generator)\n",
    "resolution_wh = frame.shape[1], frame.shape[0]\n",
    "\n",
    "for frame in frames_generator:\n",
    "    results = model(frame, verbose=False, device=device, conf=0.3)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    detections = detections.with_nms(threshold=0.7)\n",
    "    detections = tracker.update_with_detections(detections)\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    annotated_frame = COLOR_ANNOTATOR.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=detections,\n",
    "    )\n",
    "\n",
    "    labels = [\n",
    "        f\"#{tracker_id}\"\n",
    "        for tracker_id in detections.tracker_id\n",
    "    ]\n",
    "\n",
    "    annotated_frame = LABEL_ANNOTATOR.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=detections,\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"Processed Video\", annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf5c37-808f-479c-8d92-55b452137182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
