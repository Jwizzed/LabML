{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c62a10e-9128-440e-a507-277387fffb13",
   "metadata": {},
   "source": [
    "# Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2bfdf80-4457-45c0-950a-cf3e67a9ee3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T06:14:13.639484300Z",
     "start_time": "2024-03-23T06:14:13.046903100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Downloads\\DeepFashion2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b73e6b-9432-499c-9368-c5e0f7899f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T06:14:20.900903600Z",
     "start_time": "2024-03-23T06:14:14.790006400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.0rc3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q supervision inference\n",
    "import supervision as sv\n",
    "sv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49df4e63-9b3e-49a9-8028-e23d5b5ea731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-23T06:14:24.418306Z",
     "start_time": "2024-03-23T06:14:20.900903600Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q roboflow\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9946b-d5c7-4e1e-a5e4-4466cf5aa8c1",
   "metadata": {},
   "source": [
    "# Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9840a76a-f61e-4f03-b3be-2cf995d8bcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/WongKinYiu/yolov9.git\n",
    "%cd yolov9\n",
    "# # Edited albumations version\n",
    "# !pip install -r requirements.txt -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9008ef06-035a-430f-b245-b33d3c3bb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Weight\n",
    "# !mkdir weights\n",
    "# !curl -o weights/gelan-c.pt https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8516ac1-e1bb-4bbd-8e6a-23a751834c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"{HOME}/yolov9/deepfashion2-m-11k-1\"\n",
    "IMAGE_PATH = f\"{HOME}/yolov9/deepfashion2-m-11k-1/train/images\"\n",
    "WEIGHT_PATH = f\"{HOME}/yolov9/weights/gelan-c-det.pt\"\n",
    "SINGLE_IMAGE = IMAGE_PATH + \"/000001_png.rf.3efc63de2fe2bab8882abc87437bf048.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae4268-680a-4ba1-807c-ea0d44cf00c6",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f525984c-a2a5-449a-9771-e67274e215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = Roboflow(api_key=\"grBnAXmaVyCZOXlCtfQ7\")\n",
    "# project = rf.workspace(\"bmstu-lvj0c\").project(\"deepfashion2-m-11k\")\n",
    "# version = project.version(1)\n",
    "# dataset = version.download(\"yolov9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be33e79-d071-47a0-bac7-7d02c8585812",
   "metadata": {},
   "source": [
    "# Test one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8446d0fd-f2b5-43da-bc31-466c59f472df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"detect.py\", line 7, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\__init__.py\", line 130, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\lib\\cufft64_11.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights {HOME}/yolov9/runs/train/use/weights/best.pt --conf 0.1 --source {SINGLE_IMAGE} --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43fdc73-3591-4325-aa1c-57859d7d69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(filename=f\"{HOME}/yolov9/runs/detect/exp/000001_png.rf.3efc63de2fe2bab8882abc87437bf048.jpg\", width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dced07f-6759-4bf7-a012-181628636aa1",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc684abb-74f5-4b35-ac97-b21c06b20e98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train_dual.py \\\n",
    "--batch 8 --epochs 20 --img 640 --device 0 --close-mosaic 15 \\\n",
    "--data {DATA_PATH}/data.yaml \\\n",
    "--weights {HOME}/yolov9/runs/train/use/weights/best.pt \\\n",
    "--cfg models/detect/yolov9-c.yaml \\\n",
    "--hyp hyp.scratch-high.yaml \\\n",
    "--min-items 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6850680-3ce4-44fb-a582-bc5b12df9de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python val_dual.py --data {DATA_PATH}/data.yaml --img 640 --batch 16 --conf 0.001 --iou 0.7 --device 0 --weights {HOME}/yolov9/runs/train/use/weights/best.pt --save-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54443641-c2d0-411a-a426-1e3cc56fb12c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect_dual: \u001b[0mweights=['C:\\\\Users\\\\USER\\\\Downloads\\\\DeepFashion2/yolov9/runs/train/use/weights/best.pt'], source=mytest, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLO  v0.1-67-gd069079 Python-3.8.18 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060, 8187MiB)\n",
      "\n",
      "Fusing layers... \n",
      "yolov9-c summary: 604 layers, 50725998 parameters, 0 gradients, 236.8 GFLOPs\n",
      "image 1/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\1.jpg: 640x448 3 long sleeve outwears, 1 trousers, 269.1ms\n",
      "image 2/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\10.jpg: 640x640 1 long sleeve dress, 5 long sleeve tops, 2 short sleeve dresss, 9 short sleeve tops, 4 shortss, 1 skirt, 8 trouserss, 2 vests, 2 vest dresss, 36.0ms\n",
      "image 3/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\2.jpg: 640x448 1 short sleeve top, 1 trousers, 27.0ms\n",
      "image 4/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\3.jpg: 480x640 1 short sleeve top, 1 trousers, 1 vest, 269.1ms\n",
      "image 5/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\4.jpg: 384x640 1 long sleeve outwear, 1 long sleeve top, 1 trousers, 257.5ms\n",
      "image 6/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\5.jpeg: 384x640 1 long sleeve outwear, 4 long sleeve tops, 1 short sleeve top, 1 skirt, 8 trouserss, 25.0ms\n",
      "image 7/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\6.jpg: 384x640 (no detections), 25.0ms\n",
      "image 8/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\7.jpg: 480x640 2 long sleeve dresss, 2 long sleeve tops, 1 trousers, 28.0ms\n",
      "image 9/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\8.webp: 512x640 (no detections), 262.5ms\n",
      "image 10/10 C:\\Users\\USER\\Downloads\\DeepFashion2\\yolov9\\mytest\\9.jpg: 448x640 (no detections), 270.2ms\n",
      "Speed: 0.7ms pre-process, 147.0ms inference, 16.6ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\exp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !python detect_dual.py --weights {HOME}/yolov9/runs/train/use/weights/best.pt --conf 0.1 --source {SINGLE_IMAGE} --device 0\n",
    "\n",
    "!python detect_dual.py --weights {HOME}/yolov9/runs/train/use/weights/best.pt --conf 0.1 --source  --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8944309-5e67-4bcf-b0c4-8fbca1e4346e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
